{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee90548f",
   "metadata": {},
   "source": [
    "# SHOURYA GUPTA - 19BCE1704\n",
    "\n",
    "# RIDHIKA SAHNI - 19BCE1697\n",
    "\n",
    "\n",
    "# NLP PROJECT - COURT REPORTER\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f018728a",
   "metadata": {},
   "source": [
    "# Start recording - make an audio file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40da58c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python-sounddevice allows you to record audio from your microphone and store it as a NumPy array. \n",
    "#This is a handy datatype for sound processing that can be converted to WAV format for storage using the scipy.io.wavfile module.\n",
    "\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "fs = 44100  # Sample rate\n",
    "seconds = 10  # Duration of recording\n",
    "\n",
    "myrecording = sd.rec(int(seconds * fs), samplerate=fs, channels=2)\n",
    "sd.wait()  # Wait until recording is finished\n",
    "write('output.wav', fs, myrecording)  # Save as WAV file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd29966",
   "metadata": {},
   "source": [
    "# Create a file to store all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ea6b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File created \n",
    "# a = append\n",
    "#Plus sign indicates both read and write for Python create file operation.\n",
    "\n",
    "f = open(\"C:\\\\Users\\\\Shourya\\\\Desktop\\\\gender-recognition-by-voice-master\\\\document.txt\",\"a+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff098722",
   "metadata": {},
   "source": [
    "# Extract text from the audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff3f42db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: pydub in c:\\programdata\\anaconda3\\lib\\site-packages (0.25.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install SpeechRecognition pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5699c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the quality is considered a report at 370 temperatures are heading down from 19 degrees\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import soundfile\n",
    "\n",
    "data, samplerate = soundfile.read('output.wav')\n",
    "soundfile.write('new.wav', data, samplerate, subtype='PCM_16')\n",
    "\n",
    "filename = \"new.wav\"\n",
    "\n",
    "# initialize the recognizer\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# open the file\n",
    "with sr.AudioFile(filename) as source:\n",
    "    # listen for the data (load audio to memory)\n",
    "    audio_data = r.record(source)\n",
    "    # recognize (convert from speech to text)\n",
    "    \n",
    "    #API powered by Googleâ€™s AI technologies\n",
    "    text = r.recognize_google(audio_data)\n",
    "    print(text)\n",
    "    \n",
    "f.write(\"Text : \")\n",
    "f.write(text)\n",
    "f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5d0f7e",
   "metadata": {},
   "source": [
    "# Want to hear the text? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6b7c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfcc09ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "\n",
    "def SpeakText(command):\n",
    "    # Initialize the engine\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(command)\n",
    "    engine.runAndWait()\n",
    "    \n",
    "SpeakText(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fddce4",
   "metadata": {},
   "source": [
    "# Recognise the gender by voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e075d8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep learning model that is able to detect and recognize gender just by your voice tone using Tensorflow framework in Python.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tqdm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7053ae1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/cv-other-train/sample-069205.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/cv-valid-train/sample-063134.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/cv-other-train/sample-080873.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/cv-other-train/sample-105595.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/cv-valid-train/sample-144613.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                filename  gender\n",
       "0  data/cv-other-train/sample-069205.npy  female\n",
       "1  data/cv-valid-train/sample-063134.npy  female\n",
       "2  data/cv-other-train/sample-080873.npy  female\n",
       "3  data/cv-other-train/sample-105595.npy  female\n",
       "4  data/cv-valid-train/sample-144613.npy  female"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset used : https://www.kaggle.com/mozillaorg/common-voice\n",
    "# We extract these genre-labeled samples and perform gender recognition.\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Shourya\\\\Desktop\\\\gender-recognition-by-voice-master\\\\balanced-all.csv\")\n",
    "df.head()\n",
    "\n",
    "# It links each audio sample's file path to its appropriate gender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d39d4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66933</th>\n",
       "      <td>data/cv-valid-train/sample-171098.npy</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66934</th>\n",
       "      <td>data/cv-other-train/sample-022864.npy</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66935</th>\n",
       "      <td>data/cv-valid-train/sample-080933.npy</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66936</th>\n",
       "      <td>data/cv-other-train/sample-012026.npy</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66937</th>\n",
       "      <td>data/cv-other-train/sample-013841.npy</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    filename gender\n",
       "66933  data/cv-valid-train/sample-171098.npy   male\n",
       "66934  data/cv-other-train/sample-022864.npy   male\n",
       "66935  data/cv-valid-train/sample-080933.npy   male\n",
       "66936  data/cv-other-train/sample-012026.npy   male\n",
       "66937  data/cv-other-train/sample-013841.npy   male"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b84c869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 66938\n",
      "Total male samples: 33469\n",
      "Total female samples: 33469\n"
     ]
    }
   ],
   "source": [
    "#BALANCED DATASET\n",
    "\n",
    "# get total samples\n",
    "n_samples = len(df)\n",
    "# get total male samples\n",
    "n_male_samples = len(df[df['gender'] == 'male'])\n",
    "# get total female samples\n",
    "n_female_samples = len(df[df['gender'] == 'female'])\n",
    "print(\"Total samples:\", n_samples)\n",
    "print(\"Total male samples:\", n_male_samples)\n",
    "print(\"Total female samples:\", n_female_samples)\n",
    "\n",
    "# a large number of balanced audio samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2abf8a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2int = {\n",
    "    \"male\": 1,\n",
    "    \"female\": 0\n",
    "}\n",
    "\n",
    "def load_data(vector_length=128):\n",
    "\n",
    "     # function to load gender recognition dataset from `data` folder - INITIALLY\n",
    "    if not os.path.isdir(\"C:\\\\Users\\\\Shourya\\\\Desktop\\\\gender-recognition-by-voice-master\\\\results\"):\n",
    "        os.mkdir(\"C:\\\\Users\\\\Shourya\\\\Desktop\\\\gender-recognition-by-voice-master\\\\results\")\n",
    "    \n",
    "    #  After the second run, this will load from results/features.npy and results/labels.npy files as it is much faster!\n",
    "    if os.path.isfile(\"C:\\\\Users\\\\Shourya\\\\Desktop\\\\gender-recognition-by-voice-master\\\\results\\\\features.npy\") and os.path.isfile(\"C:\\\\Users\\\\Shourya\\\\Desktop\\\\gender-recognition-by-voice-master\\\\results\\\\labels.npy\"):\n",
    "        X = np.load(\"C:\\\\Users\\\\Shourya\\\\Desktop\\\\gender-recognition-by-voice-master\\\\results\\\\features.npy\")\n",
    "        y = np.load(\"C:\\\\Users\\\\Shourya\\\\Desktop\\\\gender-recognition-by-voice-master\\\\results\\\\labels.npy\")\n",
    "        return X, y\n",
    "\n",
    "    df = pd.read_csv(\"C:\\\\Users\\\\Shourya\\\\Desktop\\\\gender-recognition-by-voice-master\\\\balanced-all.csv\")\n",
    "\n",
    "    n_samples = len(df)\n",
    "\n",
    "    n_male_samples = len(df[df['gender'] == 'male'])\n",
    "    \n",
    "    n_female_samples = len(df[df['gender'] == 'female'])\n",
    "    print(\"Total samples:\", n_samples)\n",
    "    print(\"Total male samples:\", n_male_samples)\n",
    "    print(\"Total female samples:\", n_female_samples)\n",
    "    \n",
    "    # initialize an empty array for all audio features\n",
    "    X = np.zeros((n_samples, vector_length))\n",
    "    \n",
    "    # initialize an empty array for all audio labels (1 for male and 0 for female)\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    for i, (filename, gender) in tqdm.tqdm(enumerate(zip(df['filename'], df['gender'])), \"Loading data\", total=n_samples):\n",
    "        features = np.load(filename)\n",
    "        X[i] = features\n",
    "        y[i] = label2int[gender]\n",
    "\n",
    "    # save the audio features and labels into files\n",
    "    # so we won't load each one of them next run\n",
    "    np.save(\"C:\\\\Users\\\\Shourya\\\\Desktop\\\\gender-recognition-by-voice-master\\\\results\\\\features.npy\", X)\n",
    "    np.save(\"C:\\\\Users\\\\Shourya\\\\Desktop\\\\gender-recognition-by-voice-master\\\\results\\\\labels.npy\", y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1c0b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Dataset: The sample of data used to fit the model.\n",
    "# Validation data. During training, validation data infuses new data into the model that it hasnâ€™t evaluated before. Validation data provides the first test against unseen data, allowing data scientists to evaluate how well the model makes predictions based on the new data. Not all data scientists use validation data, but it can provide some helpful information to optimize hyperparameters, which influence how the model assesses data.\n",
    "\n",
    "# A hyperparameter is a parameter that is set before the learning process begins. These parameters are tunable and can directly affect how well a model trains. Some examples of hyperparameters in machine learning:\n",
    "# Learning Rate\n",
    "# Number of Epochs\n",
    "# Momentum\n",
    "# Regularization constant\n",
    "# Number of branches in a decision tree\n",
    "# Number of clusters in a clustering algorithm (like k-means)\n",
    "\n",
    "# Test Dataset: The sample of data used to provide an unbiased evaluation of a final model fit on the training dataset.\n",
    "\n",
    "def split_data(X, y, test_size=0.1, valid_size=0.1):\n",
    "    # split training set and testing set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=7)\n",
    "    # split training set and validation set\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=valid_size, random_state=7)\n",
    "   \n",
    "    return {\n",
    "        \"X_train\": X_train,\n",
    "        \"X_valid\": X_valid,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_valid\": y_valid,\n",
    "        \"y_test\": y_test\n",
    "    }\n",
    "\n",
    "# We're using sklearn's train_test_split() convenient function, which will shuffle our dataset and splits it into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b531d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "X, y = load_data()\n",
    "# split the data into training, validation and testing sets\n",
    "data = split_data(X, y, test_size=0.1, valid_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "993c4a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep feed-forward neural network with 5 hidden layers \n",
    "# Feed Forward neural - information is only processed in one direction\n",
    "\n",
    "\n",
    "def create_model(vector_length=128):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_shape=(vector_length,)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    # one output neuron with sigmoid activation function, 0 means female, 1 means male\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    # using binary crossentropy as it's male/female classification (binary)\n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
    "    # print summary of the model\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "# ReLU stands for rectified linear unit, and is a type of activation function. Mathematically, it is defined as y = max(0, x). \n",
    "# Sigmoid activation function, For small values (<-5), sigmoid returns a value close to zero, and for large values (>5) the result of the function gets close to 1.\n",
    "\n",
    "# in the output layer, the model will output the scalar 1 (or close to it) when the audio's speaker is a male, and female when it's closer to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e1c3577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 156,545\n",
      "Trainable params: 156,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25bbf99c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "848/848 [==============================] - 5s 4ms/step - loss: 0.5573 - accuracy: 0.7657 - val_loss: 0.3828 - val_accuracy: 0.8476\n",
      "Epoch 2/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.4157 - accuracy: 0.8350 - val_loss: 0.3314 - val_accuracy: 0.8680\n",
      "Epoch 3/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3841 - accuracy: 0.8509 - val_loss: 0.3181 - val_accuracy: 0.8759\n",
      "Epoch 4/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3658 - accuracy: 0.8572 - val_loss: 0.3030 - val_accuracy: 0.8782\n",
      "Epoch 5/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3518 - accuracy: 0.8650 - val_loss: 0.3070 - val_accuracy: 0.8798\n",
      "Epoch 6/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3380 - accuracy: 0.8715 - val_loss: 0.2978 - val_accuracy: 0.8788\n",
      "Epoch 7/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3272 - accuracy: 0.8730 - val_loss: 0.2771 - val_accuracy: 0.8910\n",
      "Epoch 8/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.3219 - accuracy: 0.8758 - val_loss: 0.2774 - val_accuracy: 0.8946\n",
      "Epoch 9/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.3183 - accuracy: 0.8768 - val_loss: 0.2697 - val_accuracy: 0.8948\n",
      "Epoch 10/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3095 - accuracy: 0.8822 - val_loss: 0.2713 - val_accuracy: 0.8976\n",
      "Epoch 11/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.3029 - accuracy: 0.8844 - val_loss: 0.2622 - val_accuracy: 0.8963\n",
      "Epoch 12/100\n",
      "848/848 [==============================] - 3s 3ms/step - loss: 0.2993 - accuracy: 0.8847 - val_loss: 0.2771 - val_accuracy: 0.8933\n",
      "Epoch 13/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2932 - accuracy: 0.8868 - val_loss: 0.2668 - val_accuracy: 0.9014\n",
      "Epoch 14/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2925 - accuracy: 0.8890 - val_loss: 0.2525 - val_accuracy: 0.9042\n",
      "Epoch 15/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2900 - accuracy: 0.8907 - val_loss: 0.2542 - val_accuracy: 0.9067\n",
      "Epoch 16/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.2876 - accuracy: 0.8917 - val_loss: 0.2625 - val_accuracy: 0.9019\n",
      "Epoch 17/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.2856 - accuracy: 0.8931 - val_loss: 0.2532 - val_accuracy: 0.9051\n",
      "Epoch 18/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.2842 - accuracy: 0.8932 - val_loss: 0.2508 - val_accuracy: 0.9044\n",
      "Epoch 19/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.2802 - accuracy: 0.8942 - val_loss: 0.2495 - val_accuracy: 0.9087\n",
      "Epoch 20/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.2844 - accuracy: 0.8926 - val_loss: 0.2467 - val_accuracy: 0.9090\n",
      "Epoch 21/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.2783 - accuracy: 0.8949 - val_loss: 0.2474 - val_accuracy: 0.9074\n",
      "Epoch 22/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.2730 - accuracy: 0.8975 - val_loss: 0.2382 - val_accuracy: 0.9117\n",
      "Epoch 23/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.2725 - accuracy: 0.8951 - val_loss: 0.2434 - val_accuracy: 0.9097\n",
      "Epoch 24/100\n",
      "848/848 [==============================] - 5s 6ms/step - loss: 0.2717 - accuracy: 0.8991 - val_loss: 0.2337 - val_accuracy: 0.9120\n",
      "Epoch 25/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2737 - accuracy: 0.8982 - val_loss: 0.2593 - val_accuracy: 0.9059\n",
      "Epoch 26/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.2727 - accuracy: 0.8982 - val_loss: 0.2460 - val_accuracy: 0.9094\n",
      "Epoch 27/100\n",
      "848/848 [==============================] - 3s 3ms/step - loss: 0.2717 - accuracy: 0.8982 - val_loss: 0.2432 - val_accuracy: 0.9084\n",
      "Epoch 28/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2660 - accuracy: 0.9004 - val_loss: 0.2307 - val_accuracy: 0.9155\n",
      "Epoch 29/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2653 - accuracy: 0.9020 - val_loss: 0.2394 - val_accuracy: 0.9144\n",
      "Epoch 30/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2657 - accuracy: 0.8999 - val_loss: 0.2293 - val_accuracy: 0.9119\n",
      "Epoch 31/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2638 - accuracy: 0.9002 - val_loss: 0.2532 - val_accuracy: 0.9052\n",
      "Epoch 32/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.2596 - accuracy: 0.9024 - val_loss: 0.2313 - val_accuracy: 0.9150\n",
      "Epoch 33/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2638 - accuracy: 0.9015 - val_loss: 0.2312 - val_accuracy: 0.9157\n",
      "Epoch 34/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.2595 - accuracy: 0.9036 - val_loss: 0.2349 - val_accuracy: 0.9115\n",
      "Epoch 35/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.2604 - accuracy: 0.9022 - val_loss: 0.2278 - val_accuracy: 0.9152\n",
      "Epoch 36/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.2636 - accuracy: 0.9026 - val_loss: 0.2326 - val_accuracy: 0.9112\n",
      "Epoch 37/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.2563 - accuracy: 0.9049 - val_loss: 0.2242 - val_accuracy: 0.9149\n",
      "Epoch 38/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.2564 - accuracy: 0.9054 - val_loss: 0.2245 - val_accuracy: 0.9147\n",
      "Epoch 39/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.2597 - accuracy: 0.9035 - val_loss: 0.2335 - val_accuracy: 0.9134\n",
      "Epoch 40/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.2580 - accuracy: 0.9044 - val_loss: 0.2215 - val_accuracy: 0.9167\n",
      "Epoch 41/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.2603 - accuracy: 0.9043 - val_loss: 0.2271 - val_accuracy: 0.9134\n",
      "Epoch 42/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.2565 - accuracy: 0.9061 - val_loss: 0.2268 - val_accuracy: 0.9152\n",
      "Epoch 43/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.2535 - accuracy: 0.9057 - val_loss: 0.2203 - val_accuracy: 0.9175\n",
      "Epoch 44/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2580 - accuracy: 0.9054 - val_loss: 0.2305 - val_accuracy: 0.9137\n",
      "Epoch 45/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.2597 - accuracy: 0.9025 - val_loss: 0.2250 - val_accuracy: 0.9173\n",
      "Epoch 46/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.2626 - accuracy: 0.9027 - val_loss: 0.2233 - val_accuracy: 0.9154\n",
      "Epoch 47/100\n",
      "848/848 [==============================] - 3s 4ms/step - loss: 0.2573 - accuracy: 0.9052 - val_loss: 0.2308 - val_accuracy: 0.9172\n",
      "Epoch 48/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.2555 - accuracy: 0.9051 - val_loss: 0.2309 - val_accuracy: 0.9132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2855cd998e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use tensorboard to view metrics\n",
    "tensorboard = TensorBoard(log_dir=\"logs\")\n",
    "\n",
    "# define early stopping to stop training after 5 epochs of not improving\n",
    "early_stopping = EarlyStopping(mode=\"min\", patience=5, restore_best_weights=True)\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "# train the model using the training set and validating using validation set\n",
    "model.fit(data[\"X_train\"], data[\"y_train\"], epochs=epochs, batch_size=batch_size, validation_data=(data[\"X_valid\"], data[\"y_valid\"]),\n",
    "          callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8c770cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to a file\n",
    "model.save(\"C:\\\\Users\\\\Shourya\\\\Desktop\\\\gender-recognition-by-voice-master\\\\results\\\\model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be15f6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model using 6694 samples...\n",
      "Loss: 0.2230\n",
      "Accuracy: 91.87%\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model using the testing set\n",
    "print(f\"Evaluating the model using {len(data['X_test'])} samples...\")\n",
    "loss, accuracy = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "print(f\"Loss: {loss:.4f}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d7da145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Extract features from that audio and feed it to the model to retrieve results\n",
    "\n",
    "def extract_feature(file_name, **kwargs):\n",
    "    \"\"\"\n",
    "    Extract feature from audio file `file_name`\n",
    "        Features supported:\n",
    "            - MFCC (mfcc)\n",
    "            - Chroma (chroma)\n",
    "            - MEL Spectrogram Frequency (mel)\n",
    "            - Contrast (contrast)\n",
    "            - Tonnetz (tonnetz)\n",
    "        e.g:\n",
    "        `features = extract_feature(path, mel=True, mfcc=True)`\n",
    "    \"\"\"\n",
    "    mfcc = kwargs.get(\"mfcc\")\n",
    "    chroma = kwargs.get(\"chroma\")\n",
    "    mel = kwargs.get(\"mel\")\n",
    "    contrast = kwargs.get(\"contrast\")\n",
    "    tonnetz = kwargs.get(\"tonnetz\")\n",
    "    X, sample_rate = librosa.core.load(file_name)\n",
    "    if chroma or contrast:\n",
    "        stft = np.abs(librosa.stft(X))\n",
    "    result = np.array([])\n",
    "    if mfcc:\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "        result = np.hstack((result, mfccs))\n",
    "    if chroma:\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, chroma))\n",
    "    if mel:\n",
    "        mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, mel))\n",
    "    if contrast:\n",
    "        contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, contrast))\n",
    "    if tonnetz:\n",
    "        tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, tonnetz))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54b67a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 156,545\n",
      "Trainable params: 156,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Result: male\n",
      "Probabilities::: Male: 86.14%    Female: 13.86%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# audio file path passed from the command line from test folder\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(description=\"\"\"Gender recognition script, this will load the model you trained, \n",
    "                                    and perform inference on a sample you provide (either using your voice or a file)\"\"\")\n",
    "parser.add_argument(\"-f\", \"--file\", help=\"The path to the file, preferred to be in WAV format\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "# But here, we pass our own audio file - for better evaluation\n",
    "\n",
    "file = \"C:\\\\Users\\\\Shourya\\\\output.wav\"\n",
    "\n",
    "#file = args.file\n",
    "\n",
    "\n",
    "\n",
    "# construct the model\n",
    "model = create_model()\n",
    "# load the saved/trained weights\n",
    "model.load_weights(\"C:\\\\Users\\\\Shourya\\\\Desktop\\\\gender-recognition-by-voice-master\\\\results\\\\model.h5\")\n",
    "\n",
    "\n",
    "#if not file or not os.path.isfile(file):\n",
    "    # if file not provided, or it doesn't exist, use your voice\n",
    "    #print(\"Please talk\")\n",
    "    # put the file name here\n",
    "    #file = \"test.wav\"\n",
    "    # record the file (start talking)\n",
    "    #record_to_file(file)\n",
    "\n",
    "    \n",
    "# extract features and reshape it\n",
    "features = extract_feature(file, mel=True).reshape(1, -1)\n",
    "# predict the gender!\n",
    "male_prob = model.predict(features)[0][0]\n",
    "female_prob = 1 - male_prob\n",
    "gender = \"male\" if male_prob > female_prob else \"female\"\n",
    "# show the result!\n",
    "print(\"Result:\", gender)\n",
    "print(f\"Probabilities::: Male: {male_prob*100:.2f}%    Female: {female_prob*100:.2f}%\")\n",
    "\n",
    "f.write(\"Gender : \")\n",
    "f.write(gender)\n",
    "f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2377d2cf",
   "metadata": {},
   "source": [
    "# Different outputs to show gender recognition by voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bcfe2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 156,545\n",
      "Trainable params: 156,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Result: female\n",
      "Probabilities::: Male: 0.04%    Female: 99.96%\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description=\"\"\"Gender recognition script, this will load the model you trained, \n",
    "                                    and perform inference on a sample you provide (either using your voice or a file)\"\"\")\n",
    "parser.add_argument(\"-f\", \"--file\", help=\"The path to the file, preferred to be in WAV format\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "file = \"C:\\\\Users\\\\Shourya\\\\Desktop\\\\gender-recognition-by-voice-master\\\\shourya1.wav\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# construct the model\n",
    "model = create_model()\n",
    "\n",
    "model.load_weights(\"C:\\\\Users\\\\Shourya\\\\Desktop\\\\gender-recognition-by-voice-master\\\\results\\\\model.h5\")\n",
    "\n",
    "\n",
    "#if not file or not os.path.isfile(file):\n",
    "    # if file not provided, or it doesn't exist, use your voice\n",
    "    #print(\"Please talk\")\n",
    "    # put the file name here\n",
    "    #file = \"test.wav\"\n",
    "    # record the file (start talking)\n",
    "    #record_to_file(file)\n",
    "\n",
    "    \n",
    "\n",
    "features = extract_feature(file, mel=True).reshape(1, -1)\n",
    "\n",
    "\n",
    "male_prob = model.predict(features)[0][0]\n",
    "female_prob = 1 - male_prob\n",
    "gender = \"male\" if male_prob > female_prob else \"female\"\n",
    "\n",
    "print(\"Result:\", gender)\n",
    "print(f\"Probabilities::: Male: {male_prob*100:.2f}%    Female: {female_prob*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e67b8e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 156,545\n",
      "Trainable params: 156,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Result: male\n",
      "Probabilities::: Male: 89.05%    Female: 10.95%\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description=\"\"\"Gender recognition script, this will load the model you trained, \n",
    "                                    and perform inference on a sample you provide (either using your voice or a file)\"\"\")\n",
    "parser.add_argument(\"-f\", \"--file\", help=\"The path to the file, preferred to be in WAV format\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "file = \"C:\\\\Users\\\\Shourya\\\\Desktop\\\\gender-recognition-by-voice-master\\\\ritik.wav\"\n",
    "\n",
    "#file = args.file\n",
    "\n",
    "\n",
    "\n",
    "# construct the model\n",
    "model = create_model()\n",
    "# load the saved/trained weights\n",
    "model.load_weights(\"C:\\\\Users\\\\Shourya\\\\Desktop\\\\gender-recognition-by-voice-master\\\\results\\\\model.h5\")\n",
    "\n",
    "\n",
    "#if not file or not os.path.isfile(file):\n",
    "    # if file not provided, or it doesn't exist, use your voice\n",
    "    #print(\"Please talk\")\n",
    "    # put the file name here\n",
    "    #file = \"test.wav\"\n",
    "    # record the file (start talking)\n",
    "    #record_to_file(file)\n",
    "\n",
    "    \n",
    "# extract features and reshape it\n",
    "features = extract_feature(file, mel=True).reshape(1, -1)\n",
    "# predict the gender!\n",
    "male_prob = model.predict(features)[0][0]\n",
    "female_prob = 1 - male_prob\n",
    "gender = \"male\" if male_prob > female_prob else \"female\"\n",
    "# show the result!\n",
    "print(\"Result:\", gender)\n",
    "print(f\"Probabilities::: Male: {male_prob*100:.2f}%    Female: {female_prob*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "852d4323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 156,545\n",
      "Trainable params: 156,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Result: female\n",
      "Probabilities::: Male: 3.37%    Female: 96.63%\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description=\"\"\"Gender recognition script, this will load the model you trained, \n",
    "                                    and perform inference on a sample you provide (either using your voice or a file)\"\"\")\n",
    "parser.add_argument(\"-f\", \"--file\", help=\"The path to the file, preferred to be in WAV format\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "file = \"C:\\\\Users\\\\Shourya\\\\Desktop\\\\gender-recognition-by-voice-master\\\\shourya_proj.wav\"\n",
    "\n",
    "#file = args.file\n",
    "\n",
    "\n",
    "\n",
    "# construct the model\n",
    "model = create_model()\n",
    "# load the saved/trained weights\n",
    "model.load_weights(\"C:\\\\Users\\\\Shourya\\\\Desktop\\\\gender-recognition-by-voice-master\\\\results\\\\model.h5\")\n",
    "\n",
    "\n",
    "#if not file or not os.path.isfile(file):\n",
    "    # if file not provided, or it doesn't exist, use your voice\n",
    "    #print(\"Please talk\")\n",
    "    # put the file name here\n",
    "    #file = \"test.wav\"\n",
    "    # record the file (start talking)\n",
    "    #record_to_file(file)\n",
    "\n",
    "    \n",
    "# extract features and reshape it\n",
    "features = extract_feature(file, mel=True).reshape(1, -1)\n",
    "# predict the gender!\n",
    "male_prob = model.predict(features)[0][0]\n",
    "female_prob = 1 - male_prob\n",
    "gender = \"male\" if male_prob > female_prob else \"female\"\n",
    "# show the result!\n",
    "print(\"Result:\", gender)\n",
    "print(f\"Probabilities::: Male: {male_prob*100:.2f}%    Female: {female_prob*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42c56cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 156,545\n",
      "Trainable params: 156,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002856ECA6B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Result: female\n",
      "Probabilities::: Male: 0.10%    Female: 99.90%\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description=\"\"\"Gender recognition script, this will load the model you trained, \n",
    "                                    and perform inference on a sample you provide (either using your voice or a file)\"\"\")\n",
    "parser.add_argument(\"-f\", \"--file\", help=\"The path to the file, preferred to be in WAV format\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "file = \"C:\\\\Users\\\\Shourya\\\\Desktop\\\\gender-recognition-by-voice-master\\\\ridhika.wav\"\n",
    "\n",
    "#file = args.file\n",
    "\n",
    "\n",
    "\n",
    "# construct the model\n",
    "model = create_model()\n",
    "# load the saved/trained weights\n",
    "model.load_weights(\"C:\\\\Users\\\\Shourya\\\\Desktop\\\\gender-recognition-by-voice-master\\\\results\\\\model.h5\")\n",
    "\n",
    "\n",
    "#if not file or not os.path.isfile(file):\n",
    "    # if file not provided, or it doesn't exist, use your voice\n",
    "    #print(\"Please talk\")\n",
    "    # put the file name here\n",
    "    #file = \"test.wav\"\n",
    "    # record the file (start talking)\n",
    "    #record_to_file(file)\n",
    "\n",
    "    \n",
    "# extract features and reshape it\n",
    "features = extract_feature(file, mel=True).reshape(1, -1)\n",
    "# predict the gender!\n",
    "male_prob = model.predict(features)[0][0]\n",
    "female_prob = 1 - male_prob\n",
    "gender = \"male\" if male_prob > female_prob else \"female\"\n",
    "# show the result!\n",
    "print(\"Result:\", gender)\n",
    "print(f\"Probabilities::: Male: {male_prob*100:.2f}%    Female: {female_prob*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "584446f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099178d7",
   "metadata": {},
   "source": [
    "# Print the generated document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70892928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text : Natural Language Processing project I am trying to make a speech recognizer\n",
      "Gender : female\n",
      "Text : Language Processing quotes and I am trying to make a speech recognizer\n",
      "Gender : female\n",
      "Text : the quality is considered a report at 370 temperatures are heading down from 19 degrees\n",
      "Gender : male\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"C:\\\\Users\\\\Shourya\\\\Desktop\\\\gender-recognition-by-voice-master\\\\document.txt\", \"r+\") as file1:\n",
    "    # Reading form a file\n",
    "    print(file1.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37b4201",
   "metadata": {},
   "source": [
    "# Thank you :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
